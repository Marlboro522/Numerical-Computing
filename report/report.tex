\documentclass[12pt]{article}
\usepackage{amsmath, amssymb, graphicx}

\title{CS 4600/5600 Numerical Computing\\ Homework 1}
\author{Raja}
\date{Fall 2024}

\begin{document}

\maketitle

\section*{Problem 2: Roots - Open Methods}

\subsection*{(b) Newton-Raphson Method}

Given the function:
\[
f(x) = x^3 - 6x^2 + 11x - 6.1
\]

We need to determine the largest positive root using the Newton-Raphson method, starting with \(x_0 = 3.5\).

The Newton-Raphson iteration formula is:
\[
x_{i+1} = x_i - \frac{f(x_i)}{f'(x_i)}
\]

First, we find the derivative of \(f(x)\):
\[
f'(x) = 3x^2 - 12x + 11
\]

Starting with \(x_0 = 3.5\):
\[
f(3.5) = (3.5)^3 - 6(3.5)^2 + 11(3.5) - 6.1 = 1.775
\]
\[
f'(3.5) = 3(3.5)^2 - 12(3.5) + 11 = 5.75
\]

First iteration:
\[
x_1 = 3.5 - \frac{1.775}{5.75} \approx 3.1913043
\]

Second iteration:
\[
f(3.1913043)  \approx 0.399408
\]
\[
f'(3.1913043)  \approx 3.2576178
\]
\[
x_2 \approx 3.068698
\]

Third iteration:
\[
f(3.068698) = (3.068698)^3 - 6(3.068698)^2 + 11(3.068698) - 6.1 \approx 0.0518784
\]
\[
f'(3.068698) = 3(3.068698)^2 - 12(3.068698) + 11 \approx 2.426346
\]
\[
x_3 = 3.068698 - \frac{0.518784}{2.426346} \approx 3.0473166
\]

The largest positive root after three iterations is approximately \(x \approx 3.0473166\).

\subsection*{(c) Modified Secant Method}

Using the same function \(f(x) = x^3 - 6x^2 + 11x - 6.1\), we apply the modified secant method with \(x_0 = 3.5\) and \(\delta = 0.01\).

The modified secant method iteration formula is:
\[
x_{i+1} = x_n - \frac{\delta x_i f(x_i)}{f(x_i + \delta x_i) - f(x_i)}
\]

\begin{center}
    \begin{tabular}{||c c c||} 
     \hline
     Iteration & $x_i$ & $x_{i+1}$ \\ [0.5ex] 
     \hline\hline
     0 & 3.5 & 3.1995967\\ 
     \hline
     1 & 3.1995967 & 3.0753234  \\
     \hline
     2 & 3.0753234 & 3.04881822 \\
     \hline
     3 & 3.04881822 & 3.0467729 \\
     \hline
     4 & 3.0467729 & 3.0466842863 \\
     \hline
    \end{tabular}
\end{center}

The largest positive root after five iterations \\
is approximately \(x \approx 3.0466842863\).

\section*{Problem 4: Optimization}

Given the function:
\[
f(x) = 4x - 1.8x^2 + 1.2x^3 - 0.3x^4
\]

\subsection*{(b) Prove the function is concave for all values of \(x\)}

A function is concave if its second derivative is negative for all values of \(x\).

First, we find the first derivative of \(f(x)\):
\[
f'(x) = 4 - 3.6x + 3.6x^2 - 1.2x^3
\]

Now, we find the second derivative:
\[
f''(x) = -3.6 + 7.2x - 3.6x^2
\]

For \(f''(x)\) to be negative for all values of \(x\), we need to check its sign:
\[
f''(x) = -3.6 + 7.2x - 3.6x^2
\]

Let's analyze the roots of \(f''(x)\):
\[
-3.6 + 7.2x - 3.6x^2 = 0
\]
\[
3.6x^2 - 7.2x + 3.6 = 0
\]
\[
x^2 - 2x + 1 = 0
\]
\[
(x - 1)^2 = 0
\]
\[
x = 1
\]

At \(x = 1\):
\[
f''(1) = -3.6 + 7.2(1) - 3.6(1)^2 = -3.6 + 7.2 - 3.6 = 0
\]

The second derivative is zero at \(x = 1\), so we need to analyze the behavior around \(x = 1\):
For \(x < 1\), \(f''(x)\) is negative.
For \(x > 1\), \(f''(x)\) is negative.

 \(f''(x)\) doesn't change sign, the function is concave for all values of \(x\).

\subsection*{Problem 5: Optimization}

Given the function:
\[
f(x_1, x_2) = \frac{1}{2}(x_1^2 - x_2)^2 + \frac{1}{2}(1 - x_1)^2
\]

\subsection*{(a) Minimum point}

To find the minimum point, we need to find the Hessian Matrix:
\[
% H = \left( \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2} \right) = 0
H = \begin{pmatrix}
6x_1^2 - 2x_2 + 1 & -2x_1 \\
-2x_1 & 1
\end{pmatrix}
\]

Simplifying, we find the critical point is:
\[
(x_1, x_2) = (1, 1)
\]

After substituing the \((x_1, x_2)\) as (1,1) the \(\det{H}\) is greater than 0.

Therefore, the critical point is the minimum point of the function.

\subsection*{(b) Newton's Method Iteration}

Using the starting point \(\begin{pmatrix} 2 \\ 2 \end{pmatrix}\), we perform one iteration of Newton's method for minimizing \(f\).

The Hessian matrix is:
\[
H = \begin{pmatrix}
6x_1^2 - 2x_2 + 1 & -2x_1 \\
-2x_1 & 1
\end{pmatrix}
\]

The gradient matrix would be \(\begin{pmatrix}
    \frac{\partial f} { \partial x_1} \\
    \frac{\partial f}  {\partial x_2}
\end{pmatrix}\)
\\ 
\(
    \frac{\partial f} {\partial x_1} = 2x_1(x_1^2 - x_2) - (1 - x_1) \\
    \frac{\partial f}  {\partial x_2} = -(x_1^2 - x_2)
\)

The gradient at \(\begin{pmatrix} 2 \\ 2 \end{pmatrix}\) is:
\[
\nabla f = \begin{pmatrix}
2x_1(x_1^2 - x_2) - (1 - x_1) \\
-(x_1^2 - x_2)
\end{pmatrix}
= \begin{pmatrix}
2(2)(4 - 2) - (1 - 2) \\
-(4 - 2)
\end{pmatrix}
= \begin{pmatrix}
9 \\
-2
\end{pmatrix}
\]

The Hessian at \(\begin{pmatrix} 2 \\ 2 \end{pmatrix}\) is:
\[
H = \begin{pmatrix}
6(2)^2 - 2(2) + 1 & -2(2) \\
-2(2) & 1
\end{pmatrix}
= \begin{pmatrix}
21 & -4 \\
-4 & 1
\end{pmatrix}
\]

The Newton step is:
\[
\Delta x = -H^{-1} \nabla f
\]

We need to invert the Hessian:

Formula:
\[
H^{-1} = \frac{1}{ad - bc} \begin{pmatrix}
d & -b \\
-c & a
\end{pmatrix}
\]

\[
H^{-1} = \frac{1}{21 \cdot 1 - (-4 \cdot -4)} \begin{pmatrix}
1 & 4 \\
4 & 21
\end{pmatrix}
= \frac{1}{5} \begin{pmatrix}
1 & 4 \\
4 & 21
\end{pmatrix}
= \begin{pmatrix}
0.2 & 0.8 \\
0.8 & 4.2
\end{pmatrix}
\]

The Newton step is:\\
$
\Delta x = - \begin{pmatrix}
0.2 & 0.8 \\
0.8 & 4.2
\end{pmatrix} \begin{pmatrix}
9 \\
-2
\end{pmatrix}\\
= - \begin{pmatrix}
 0.2 \cdot 9 + 0.8 \cdot (-2) \\
 0.8 \cdot 9+ 4.2\cdot (-2)
\end{pmatrix}\\
= - \begin{pmatrix}
1.8 -1.6 \\
7.2 -8.4
\end{pmatrix}\\
= - \begin{pmatrix}
0.2 \\
-1.2
\end{pmatrix}\\
= \begin{pmatrix}
-0.2 \\
1.2
\end{pmatrix}
$

The new point after one iteration is:
\[
\begin{pmatrix}
2 \\
2
\end{pmatrix}
+ \begin{pmatrix}
-0.2 \\
1.2
\end{pmatrix}
= \begin{pmatrix}
1.8\\
2.2
\end{pmatrix}
\]

To determine if this is a good step or a bad one, we need to evaluate the function at this new point,
and see how closer it is the point we found as minima which is \((1,1)\)\\
if \(f(1.8,2.2) < f(2,2)\) then it would be a good step because\\
\(
    f(1.8,2.2) = \frac{1}{2}(1.8^2 - 2.2)^2 + \frac{1}{2}(1 - 1.8)^2 = 0.02 \\
    f(2,2) = \frac{1}{2}(2^2 - 2)^2 + \frac{1}{2}(1 - 2)^2 = 1\\
    f(1,1) = \frac{1}{2}(1^2 - 1)^2 + \frac{1}{2}(1 - 1)^2 = 0
    \)
\paragraph*{Sense of why it is good step: }When we evaluate the function with the given values, we can see that new values are making the function to near 0, which is the minimum value at point (1,1) \\
Therefore, the new point is a good step in this sense.

\paragraph*{Sense of why this could be a bad step: }By lookinng at just the values of of \(x_1\) and \(x_2\) we can see that \(x_2\) value increased \\
There is an 

\section*{Graduate Problem: }
\paragraph*{My understandding:}
The projectile motion is parabolic and should pass thorough the point, \((x,h2)\) inorder to clear the roof. 
The hint says the coverage is maximized when the water just clears the height of the roof, which is h2. 

The equation of the projectile motion is given by:
\(y = \tan\theta(x) - \frac{gx^2}{2(ucos\theta)^2}\).
I need to think about this analytically. 

Ok, so this is a two dimenstional function, 
Intuition says if the angle goes over 45, the water would be nearing 0 on x-axis. 
\end{document}